<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Safe Bimanual Teleoperation with Language-Guided Collision Avoidance.">
  <meta property="og:title" content="Safe Bimanual Teleoperation with Language-Guided Collision Avoidance." />
  <meta property="og:description"
    content="Website for the paper: Safe Bimanual Teleoperation with Language-Guided Collision Avoidance" />

  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/telepresence_concept_figure.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <!-- <meta name="twitter:title" content="NOSALRO">
  <meta name="twitter:description" content="https://x.com/nosalro"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image"
    content="https://github.com/NOSALRO/nosalro.github.io/blob/main/src/images/nosalro_logov1.jpg?raw=true">
  <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords"
    content="teleoperation, bimanual teleoperation, robot teleoperation, collision avoidance, vision-language grounding, VR teleoperation, safe teleoperation, immersive control, human-robot interaction, language-driven robotics, voice-activated robotics, robot learning, manipulation in cluttered environments, visual grounding, whole-body control, behavior cloning, robot data collection, speech-based robot control, virtual reality robotics, intent-aware collision avoidance.">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Safe Bimanual Teleoperation with Language-Guided Collision Avoidance Website</title>
  <link rel="icon" type="image/x-icon" href="static/images/hucebot_logo.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="static/css/bibtex.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>

  <!-- Title Authors Links -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Safe Bimanual Teleoperation with Language-Guided Collision
              Avoidance Website</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://dtotsila.github.io/" target="_blank">Dionis Totsila</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://cdonosok.github.io/" target="_blank">Clemente Donoso Krauss</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://members.loria.fr/EMingoHoffman/" target="_blank">Enrico Mingo Hoffman</a>,
              </span>
              <span class="author-block">
                <a href="https://members.loria.fr/JBMouret/" target="_blank">Jean-Baptiste Mouret</a>,
              </span>
              <span class="author-block">
                <a href="https://members.loria.fr/SIvaldi/" target="_blank">Serena Ivaldi</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"> All authors are with Inria, CNRS, Loria and Universite de Lorraine,
                France.<br>
                <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                <br>Submitted to IEEE Conference on Telepresence 2025</span>

            </div>

            <div class="column has-text-centered">
              <!-- <div class="publication-links"> -->
              <!-- Arxiv PDF link -->
              <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

              <!-- Supplementary PDF link -->
              <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

              <!-- Github link -->
              <span class="link-block">
                <a href="#" target="_self"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                </a>
              </span>

              <!-- ArXiv abstract Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2507.04791" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv </span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>
  <section class="hero is-small ">
    <div class="hero-body">
      <div class="container">
        <!-- Paper video. -->
        <!-- <h2 class="title is-3">Video Presentation</h2> -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">

            <div class="publication-video">
              <!-- Youtube embed code here -->
              <iframe width="560" height="315" src="https://www.youtube.com/embed/AkiE5izSgMk?si=QZyWSgdGww3ecnJH"
                title="YouTube video player" frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End Title Authors Links -->
  <!-- End Concept Figure -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Teleoperating precise bimanual manipulations in
              cluttered environments is challenging for operators, who often
              struggle with limited spatial perception and difficulty estimating
              distances between target objects, the robot's body, obstacles,
              and the surrounding environment. To address the challenge
              of limited spatial perception and distance estimation during
              teleoperation, local robot perception and control should assist
              the operator during teleoperation. In this work, we introduce
              a safe teleoperation system that enhances operator control
              by preventing collisions in cluttered environments through
              the combination of immersive VR control and voice-activated
              collision avoidance. Using HTC Vive controllers, operators
              directly control a bimanual mobile manipulator, while spoken
              commands such as “avoid the yellow tool” trigger visual
              grounding and segmentation to build 3D obstacle meshes. These
              meshes are integrated into a whole-body controller to actively
              prevent collisions during teleoperation. Experiments in static,
              cluttered scenes demonstrate that our system significantly improves
              operational safety without compromising task efficiency.
            </p>
            <section class="hero teaser">
              <div class="container is-max-desktop">
                <div class="hero-body">
                  <img src="static/images/telepresence_concept_figure.png" alt="ANDPs Pipeline" style="width:100%;">

                  The operator teleoperates both arms of the robot using VR controllers while instructing the system via
                  speech
                  to avoid the “yellow sauce” and the “red box”. This enables intent-aware collision avoidance.

                </div>
              </div>
            </section>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Prompts -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">System Prompt</h2>
        <div>
          <div class="item">
            <div class="prompt">
              <div class="system-prompt">
                <p class="subtitle has-text-justified">
                  System Prompt: <br>
                  "You are an intelligent assistant integrated into a robotic collision avoidance system.<br><br>
                  Your task is to interpret user prompts and convert them into structured JSON responses that update the robot's avoidance list. The robot maintains a 'Cache' of currently detected objects. Users may instruct the system to avoid new objects or stop avoiding previously avoided ones.<br><br>
                  Your output must strictly follow this format:<br><br>
                  {<br>
                  &nbsp;&nbsp;\"chain_of_thought\": \"step-by-step reasoning in one string, explaining how you interpreted the prompt, what objects are relevant, and why you are adding or removing them. Mention that irrelevant lists (add or remove) should be left empty.\",<br>
                  &nbsp;&nbsp;\"add\": [\"object1\", \"object2\", ...],<br>
                  &nbsp;&nbsp;\"remove\": [\"objectA\", \"objectB\", ...]<br>
                  }<br><br>
                  Instructions:<br>
                  - First, identify the intent behind the user's prompt: are they asking to avoid something (add) or stop avoiding something (remove)?<br>
                  - Use fuzzy matching or reasonable interpretation for noisy inputs (e.g., 'mustred' → 'mustard').<br>
                  - Only include objects that match or closely resemble items in the Cache. If the Cache is empty, assume user-intended items should still be added to the avoidance list.<br>
                  - Leave the \"add\" or \"remove\" list empty if the action is not needed.<br>
                  - The \"chain_of_thought\" must clearly explain your logic for each decision.<br>
                  - Output valid JSON only—no extra text or explanations outside the JSON structure. Keep in mind that when you are adding an object, do not change the way the human referred to it. Also translate everything to English. 'Avoid' means add to the collision avoidance list."
                </p>
              </div>
              <div class="examples subtitle">
                <p class="examples-text">
                  Examples:
                </p>

                <p class="user">
                  User: Cache: ["table", "mustard", "red box", "cup"]<br>
                  Prompt: avoid cap, remove mustred
                </p>
                <p class="assistant">
                  Response: { "chain_of_thought": "Interpreting prompt: 'avoid cap, remove mustred'. 'cap' is likely a transcription or phonetic error for 'cup', which exists in the Cache. 'mustred' is likely a transcription error for 'mustard', also in the Cache. The user wants to add 'cup' to the avoidance list and remove 'mustard' from it. When an action type is not relevant (i.e., no items to add or remove), its corresponding list should be left empty.", "add": ["cup"], "remove": ["mustard"] }
                </p>

                <p class="user">
                  User: Cache: []<br>
                  Prompt: Do not collide with the cup and the table
                </p>
                <p class="assistant">
                  Response: { "chain_of_thought": "Interpreting prompt: 'do not collide with the cup and the table'. The Cache is currently empty. 'cup' and 'table' are mentioned explicitly in the prompt. Even though they are not detected yet, we assume they are valid objects to avoid once detected. Adding 'cup' and 'table' to the avoidance list. When an action type is not relevant (i.e., no items to add or remove), its corresponding list should be left empty.", "add": ["cup", "table"], "remove": [] }
                </p>

                <p class="user">
                  User: Cache: ["banana", "apple", "bread", "mustard"]<br>
                  Prompt: Remove all except from bread
                </p>
                <p class="assistant">
                  Response: { "chain_of_thought": "Interpreting prompt: 'remove all except from bread'. 'bread' should remain in the avoidance list. All other objects in the Cache ('banana', 'apple', 'mustard') should be removed from the avoidance list. When an action type is not relevant (i.e., no items to add or remove), its corresponding list should be left empty.", "add": [], "remove": ["banana", "apple", "mustard"] }
                </p>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!--BibTex citation -->


  <!--BibTex citation -->
  <!-- <section class="section hero is-light" id="BibTeX (Preprint)">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
      <span class="keyword">@INPROCEEDINGS</span>{10769902,
      <span class="keyword">author</span>={<span class="string">Totsila, Dionis and Rouxel, Quentin and Mouret, Jean-Baptiste and Ivaldi, Serena</span>},
      <span class="keyword">booktitle</span>={<span class="string">2024 IEEE-RAS 23rd International Conference on Humanoid Robots (Humanoids)</span>},
      <span class="keyword">title</span>={<span class="string">Words2Contact: Identifying Support Contacts from Verbal Instructions Using Foundation Models</span>},
      <span class="keyword">year</span>={<span class="string">2024</span>},
      <span class="keyword">volume</span>={<span class="string">{}</span>},
      <span class="keyword">number</span>={<span class="string">{}</span>},
      <span class="keyword">pages</span>={<span class="string">9-16</span>},
      <span class="keyword">keywords</span>={<span class="string">Accuracy; Large language models; Pipelines; Natural languages; Humanoid robots; Transforms; Benchmark testing; Iterative methods; Surface treatment</span>},
      <span class="keyword">doi</span>={<span class="string">10.1109/Humanoids58906.2024.10769902</span>}}
      </code></pre>
    </div>
  </section> -->

  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <h2 class="title is-4">Acknowledgements</h2>
            <p>
              This work was supported by the EU Horizon project
              euROBIN (GA n.101070596), the France 2030 program
              through the PEPR O2R projects AS3 and PI3 (ANR-22-
              EXOD-007, ANR-22-EXOD-004), the Agence Innovation
              Défense (ATOR project), the CPER CyberEntreprises, and
              the Creativ'Lab platform of Inria/LORIA. It also benefited
              from government funding managed by the French National
              Research Agency under France 2030 via the ENACT AI
              Cluster (ANR-23-IACL-0004)

              <hr style="border-top: 1px dotted #8c8b8b;">

            <div class="content">

              <p>
                <br>
                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank">Academic
                  Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io"
                  target="_blank">Nerfies</a> project page.
                You are free to borrow the of this website, we just ask that you link back to this page in the
                footer.


                <br> This website is licensed under a <a rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                  Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>

            </div>
          </div>
        </div>
      </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>
